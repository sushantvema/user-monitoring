{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Credibility Scores: Creating Task Scores\n",
    "This notebook will include steps 2 and 3 from the User Monitoring Pipeline, which includes identifying the consensus answer from the IAA and Gold Standard data (step 2) and creating the corresponding task scores for users who completed this task (step 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hardcoded Evidence Schema\n",
    "Most of this information will be in some sort of schema file (see file 'Evidence2021_05_19-Schema.csv'), but I'm not sure where the schema file is for this specific set of tasks. Thus, I hard coded it with the schema data from https://github.com/Goodly/PEUserMonitoring/blob/master/task-schema/Evidence.txt. Getting this information with the right schema file should be fairly straightforward.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_questions = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}\n",
    "\n",
    "question_schema = {1:{'type':'select_one_nominal', 'num_choices':3},\n",
    "           2:{'type':'select_all', 'num_choices':9},\n",
    "           3:{'type':'select_one_nominal', 'num_choices':1},\n",
    "           4:{'type':'select_one_ordinal', 'num_choices':6},\n",
    "           5:{'type':'select_one_nominal', 'num_choices':5},\n",
    "           6:{'type':'select_one_nominal', 'num_choices':3},\n",
    "           7:{'type':'select_one_ordinal', 'num_choices':1},\n",
    "           8:{'type':'select_one_ordinal', 'num_choices':5},\n",
    "           9:{'type':'select_one_ordinal', 'num_choices':3},\n",
    "           10:{'type':'select_one_ordinal', 'num_choices':5},\n",
    "           11:{'type':'select_one_ordinal', 'num_choices':5},\n",
    "           12:{'type':'select_one_ordinal', 'num_choices':4},\n",
    "           13:{'type':'select_one_ordinal', 'num_choices':10},\n",
    "           14:{'type':'select_one_ordinal', 'num_choices':10}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of IAA and Gold Standard Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data\n",
    "gold = pd.read_csv('evidence_eric/evidence_eric/Covid_Evidence2020_03_21.adjudicated-edb1510f-1923-4d6f-a678-95f53d752bea-Tags.csv')\n",
    "iaa = pd.read_csv('evidence_eric/evidence_eric/Covid_Evidencev1.IAA-edb1510f-1923-4d6f-a678-95f53d752bea-Tags.csv')\n",
    "\n",
    "# getting rid of some rows where the answer was invalid, probably represents some other metadata\n",
    "iaa = iaa[iaa.answer_uuid.str.len() > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the only relevant columns for scoring for now, notice highlight data is not included here\n",
    "cols = ['answer_uuid', 'question_Number', 'agreed_Answer']\n",
    "\n",
    "# getting rid of some rows where the above columns were the same, this may represent different \n",
    "# highlights for the same question and answer?\n",
    "gold = gold[cols].drop_duplicates()\n",
    "iaa = iaa[cols].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below cells just show the format of the preprocessed IAA and Gold Standard data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_uuid</th>\n",
       "      <th>question_Number</th>\n",
       "      <th>agreed_Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73d7a14a-9ec6-404c-b2b7-a55508af3b76</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a1fb1f4-d8b7-45c0-bce5-7d4c3b91c55f</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ba2d1638-2509-4ce8-9130-39ea26d1d424</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            answer_uuid  question_Number  agreed_Answer\n",
       "0  73d7a14a-9ec6-404c-b2b7-a55508af3b76                1              1\n",
       "1  5a1fb1f4-d8b7-45c0-bce5-7d4c3b91c55f                2              1\n",
       "3  ba2d1638-2509-4ce8-9130-39ea26d1d424                2              2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_uuid</th>\n",
       "      <th>question_Number</th>\n",
       "      <th>agreed_Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73d7a14a-9ec6-404c-b2b7-a55508af3b76</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5a1fb1f4-d8b7-45c0-bce5-7d4c3b91c55f</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ba2d1638-2509-4ce8-9130-39ea26d1d424</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            answer_uuid  question_Number agreed_Answer\n",
       "0  73d7a14a-9ec6-404c-b2b7-a55508af3b76                1             1\n",
       "3  5a1fb1f4-d8b7-45c0-bce5-7d4c3b91c55f                2             1\n",
       "4  ba2d1638-2509-4ce8-9130-39ea26d1d424                2             2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iaa.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating The Answer Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consensus answer key\n",
    "consensus_answers = {}\n",
    "\n",
    "def get_answer(question, answer_source):\n",
    "    \"\"\"\n",
    "    Take in the question and the answer_source, either IAA or Gold Standard, and adds the\n",
    "    converged consensus answer to the consensus_answer answer key. This will be an single\n",
    "    int for select_one questions, or a list of ints for select_all questions.\n",
    "    \"\"\"\n",
    "    question_type = question_schema[question]['type']\n",
    "    \n",
    "    if question_type == 'select_one_nominal' or question_type == 'select_one_ordinal':\n",
    "        assert len(answer_source[answer_source.question_Number == question].agreed_Answer) == 1\n",
    "        consensus_answers[question] = answer_source[answer_source.question_Number == question].agreed_Answer.iloc[0]\n",
    "    elif question_type == 'select_all':\n",
    "        consensus_answers[question] = list(answer_source[answer_source.question_Number == question].agreed_Answer)\n",
    "    else:\n",
    "        raise ValueError('Invalid question type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a set of questions that the Gold Standard data determined converged\n",
    "gold_consensus_questions = set(gold.question_Number)\n",
    "# create a set of questions that the IAA data determined converged\n",
    "iaa_consensus_questions = set(iaa.question_Number)\n",
    "\n",
    "# uses get_answer function to fill in the consensus_answers answer key\n",
    "for question in scored_questions:\n",
    "    if question in gold_consensus_questions:\n",
    "        get_answer(question, gold)\n",
    "    elif question in iaa_consensus_questions:\n",
    "        get_answer(question, iaa)\n",
    "    else:\n",
    "        consensus_answers[question] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What the consensus key looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 1,\n",
       " 2: [1, 2, 3, 5],\n",
       " 3: -1,\n",
       " 4: 2,\n",
       " 5: 5,\n",
       " 6: '3',\n",
       " 7: 1,\n",
       " 8: 4,\n",
       " 9: 1,\n",
       " 10: 4,\n",
       " 11: 4,\n",
       " 12: 2}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consensus_answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring_select_one_nominal(question, answer):\n",
    "    \"\"\"\n",
    "    Takes in a question and the selected answer, returns a score of 0 if the consensus \n",
    "    answer is different, and 1 if the consensus answer is the same.\n",
    "    \"\"\"\n",
    "    consensus_answer = consensus_answers[question]\n",
    "    return int(consensus_answer == answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring_select_one_ordinal(question, answer):\n",
    "    \"\"\"\n",
    "    Takes in a question and the selected answer, returns a score between 0 and 1 depending\n",
    "    on how far off the answer is from the consensus answer.\n",
    "    \"\"\"\n",
    "    consensus_answer = consensus_answers[question]\n",
    "    num_choices = question_schema[question]['num_choices']\n",
    "    return 1 - (abs(answer - consensus_answer) / num_choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring_select_all(question, answer_list):\n",
    "    \"\"\"\n",
    "    Takes in a question and the selected answer, returns a score between 0 and 1 depending\n",
    "    on the accuracy ((True Positive + True Negative) / Total) of the answer selections\n",
    "    compared to the consensus answer selections.\n",
    "    \"\"\"\n",
    "    answer_set = set(answer_list)\n",
    "    consensus_answer_set = set(consensus_answers[question])\n",
    "    num_choices = question_schema[question]['num_choices']\n",
    "    \n",
    "    total_correct = 0\n",
    "    for answer in range(1, num_choices+1):\n",
    "        if (answer in answer_set) and (answer in consensus_answer_set):\n",
    "            total_correct += 1\n",
    "        elif (answer not in answer_set) and (answer not in consensus_answer_set):\n",
    "            total_correct += 1\n",
    "        else:\n",
    "            total_correct += 0\n",
    "        \n",
    "    return total_correct / num_choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(row):\n",
    "    \"\"\"\n",
    "    This is a Pandas apply function, to be applied on axis=1 (on each row).\n",
    "    Makes a call to one of scoring_select_one_nominal, scoring_select_one_ordinal, and\n",
    "    scoring_select_all depending on the type of question, returns the outputted score.\n",
    "    \n",
    "    An important note is that right now if neither IAA nor Gold Standard have a consensus\n",
    "    answer for a question, the consensus_answers answer key will contain a -1 for that \n",
    "    question. I currently assume this question should not have been answered due to it\n",
    "    being a child-question from an incorrectly answered parent question, so I score it\n",
    "    \"\"\"\n",
    "    question = int(row['question_label'])\n",
    "    answer_list = [int(i) for i in row['answer_label']]\n",
    "    \n",
    "    if consensus_answers[question] == -1:\n",
    "        return 0\n",
    "    \n",
    "    question_type = question_schema[question]['type']\n",
    "    if question_type == 'select_one_nominal':\n",
    "        return scoring_select_one_nominal(question, answer_list[0])\n",
    "    elif question_type == 'select_one_ordinal':\n",
    "        return scoring_select_one_ordinal(question, answer_list[0])\n",
    "    elif question_type == 'select_all':\n",
    "        return scoring_select_all(question, answer_list)\n",
    "    else:\n",
    "        raise ValueError('Invalid question type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the datahunt\n",
    "df_full = pd.read_csv('evidence_eric/evidence_eric/Covid_Evidencev1-Task-2224-DataHunt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# narrow down the datahunt to the relevant columns for scoring, getting rid of some rows\n",
    "# where the data for the below columns were the same, this may represent different highlights \n",
    "# for the same question and answer? not certain.\n",
    "df = df_full[['contributor_uuid', 'question_label', 'answer_label']].drop_duplicates()\n",
    "\n",
    "# the question and answer labels in the datahunt are in the form 'T1.QX' and 'T1.QX.AX'\n",
    "# the below lines strip down to only question number and answer number\n",
    "df['question_label'] = df['question_label'].str.split('Q').str[1].astype(int)\n",
    "df['answer_label'] = df['answer_label'].str.split('A').str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# we want to groupby contributor_uuid and question_label to get all the answers a user\n",
    "# selected for a particular question, to account for select_all questions. Now, the\n",
    "# granularity of df_grouped will be one row per contributor answering a question.\n",
    "df_grouped = df.groupby(['contributor_uuid', 'question_label']).agg(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we only want to score the rows with scored questions (not survey questions like 13 and 14)\n",
    "# so we'll filter those out\n",
    "df_grouped = df_grouped[df_grouped.question_label.isin(scored_questions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# using the scoring function defined above, we'll create a new column containing the scores\n",
    "# for each contributor answering a question.\n",
    "df_grouped['score'] = df_grouped.apply(scoring, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the current format of df_grouped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contributor_uuid</th>\n",
       "      <th>question_label</th>\n",
       "      <th>answer_label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00f548b7-6b63-4b47-828e-8e416b6ca0e2</td>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00f548b7-6b63-4b47-828e-8e416b6ca0e2</td>\n",
       "      <td>2</td>\n",
       "      <td>[3, 5, 8, 4]</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00f548b7-6b63-4b47-828e-8e416b6ca0e2</td>\n",
       "      <td>3</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       contributor_uuid  question_label  answer_label  \\\n",
       "0  00f548b7-6b63-4b47-828e-8e416b6ca0e2               1           [1]   \n",
       "1  00f548b7-6b63-4b47-828e-8e416b6ca0e2               2  [3, 5, 8, 4]   \n",
       "2  00f548b7-6b63-4b47-828e-8e416b6ca0e2               3           [1]   \n",
       "\n",
       "      score  \n",
       "0  1.000000  \n",
       "1  0.555556  \n",
       "2  0.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lastly, we want to get the average score for all task responses, this will be their\n",
    "# task score. this is done by a simple groupby on contributor_uuid and mean() aggregate function\n",
    "task_scores = df_grouped[['contributor_uuid', 'score']].groupby('contributor_uuid').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what the final task_scores output will look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contributor_uuid</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00f548b7-6b63-4b47-828e-8e416b6ca0e2</th>\n",
       "      <td>0.603241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>070268de-067c-463b-9ad3-5c88292d881e</th>\n",
       "      <td>0.878889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>082a8363-a579-41b4-8918-c166fec3a3a4</th>\n",
       "      <td>0.513333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>09df3ada-e5a8-4419-b78a-e0d1e9b37484</th>\n",
       "      <td>0.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>09f279ac-1c34-4a84-8972-3d92b93605a7</th>\n",
       "      <td>0.361111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0c22ce7c-4641-4bb1-97f4-7a7355f70f25</th>\n",
       "      <td>0.831481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0e51ab2d-1a03-4d18-be33-fd21a829d19b</th>\n",
       "      <td>0.754630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1b69eee8-ab95-49dd-8979-9fff7655964d</th>\n",
       "      <td>0.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21ffd986-c219-43a0-b82f-4cc460da628d</th>\n",
       "      <td>0.831481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24640f45-b90b-40dc-a848-9e03fdfbbf91</th>\n",
       "      <td>0.588889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2658cecf-829f-4b91-84fa-333e1ff2533c</th>\n",
       "      <td>0.574537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2de6fa3e-ba77-4247-97a1-ce5661997618</th>\n",
       "      <td>0.361111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3254f476-8fe5-4b93-8ab3-0a858015fde1</th>\n",
       "      <td>0.597475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348c9e41-2d9c-47fa-b13c-3ec96d70afcc</th>\n",
       "      <td>0.817284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38843a0b-310a-4083-920e-4c7431c085d9</th>\n",
       "      <td>0.789899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3de829c9-4cc0-42b6-a29b-f4d8dcb861a3</th>\n",
       "      <td>0.690909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411f7dff-e994-433c-b5c6-a7d4adf9b010</th>\n",
       "      <td>0.361111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5059cbd7-64ee-48c0-8942-583f9e6c67c2</th>\n",
       "      <td>0.361111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51f195d5-1362-4a7e-9d72-3aa9ff3c437d</th>\n",
       "      <td>0.712222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62b8fd1c-9cd2-4a31-a8a1-0641d5b8dc71</th>\n",
       "      <td>0.736869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6d82de9d-0553-47b6-b678-d0110a069663</th>\n",
       "      <td>0.593750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6e035130-fe33-4c6b-8712-1aefc4bc68de</th>\n",
       "      <td>0.514815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7c99c1f8-6853-409c-a6c4-124bdfb6489f</th>\n",
       "      <td>0.753968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85579cf2-e01c-45c5-b9e7-34b40467148d</th>\n",
       "      <td>0.828571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8f5c408e-20c1-4f79-ac52-bb772dff6b32</th>\n",
       "      <td>0.361111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90f54517-9a8b-43d1-9ea1-95ba35b465d4</th>\n",
       "      <td>0.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95dc40d9-3710-47d7-abf0-24b825a1d0c5</th>\n",
       "      <td>0.890741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981874cf-9246-4e1e-b23c-00d432126c4f</th>\n",
       "      <td>0.875309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a1646881-e64e-4139-b608-f4d4a42de866</th>\n",
       "      <td>0.604938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a2edb56d-11a9-4823-93c7-260e11d36668</th>\n",
       "      <td>0.678395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a5a60ffa-d84a-46f1-9011-38515d1c249e</th>\n",
       "      <td>0.361111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ac49bd61-73d3-475b-9dcd-e8f476c0c19b</th>\n",
       "      <td>0.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ace2c639-8cd5-403e-8b0e-1af7faddf349</th>\n",
       "      <td>0.597475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b3d267dc-896f-4bc9-8f9b-a6a942db579a</th>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ba750de9-78de-45bb-a929-873704fe71e8</th>\n",
       "      <td>0.752525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bd786026-bad5-4fa8-9a3a-38ca03a16412</th>\n",
       "      <td>0.736364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0697300-b1e0-48fd-92cd-958aa1b8a4f7</th>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0ab7c63-2f39-405a-97cf-8a0e4161c03e</th>\n",
       "      <td>0.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2ce666b-eb5f-416a-bfea-8125ff5606f3</th>\n",
       "      <td>0.670202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c3a4c4a5-1efe-4554-ab45-60f32737a52d</th>\n",
       "      <td>0.781818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cffa52fe-b6e2-433e-ba12-f36225f8ec5c</th>\n",
       "      <td>0.656566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d50137ad-8dce-4274-85c5-c2b399ce7ae0</th>\n",
       "      <td>0.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d5a1b3dc-4247-4f6f-8c2c-a11a4877cf01</th>\n",
       "      <td>0.767172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d77af5c1-a742-4613-9bb6-0260e4945899</th>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>db8307ca-1d91-4749-b1e5-ac4bb8aba075</th>\n",
       "      <td>0.716162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dc33f0ea-1670-4a8e-80a0-b10aa78bba24</th>\n",
       "      <td>0.937778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de68bbf8-46d7-45f0-9111-92e64ab9499a</th>\n",
       "      <td>0.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e1ae8875-a398-4dde-8f4e-4b21109784e3</th>\n",
       "      <td>0.891358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e7042c9b-f64c-4a6a-a8c9-f2cc7fca6866</th>\n",
       "      <td>0.834568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e8542793-c51d-4edd-9f27-f2cb6005ed39</th>\n",
       "      <td>0.686420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eddb3434-036e-4901-a4cf-02b10326e7dc</th>\n",
       "      <td>0.896296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ee0c5dfb-4021-4d7f-b62a-f9830df90514</th>\n",
       "      <td>0.758333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f7ba7233-32f2-4390-b026-16acd43954f0</th>\n",
       "      <td>0.361111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f81fbbc0-feb7-454d-b486-c24e17bccad6</th>\n",
       "      <td>0.900617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f9143626-bfe0-4e69-b652-6d1525ab4eb0</th>\n",
       "      <td>0.361111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fc3f3244-1ff1-4e88-b1cd-51368ad5a313</th>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fd6f6837-7881-4943-8129-b7ea0f0fe1b6</th>\n",
       "      <td>0.963333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         score\n",
       "contributor_uuid                              \n",
       "00f548b7-6b63-4b47-828e-8e416b6ca0e2  0.603241\n",
       "070268de-067c-463b-9ad3-5c88292d881e  0.878889\n",
       "082a8363-a579-41b4-8918-c166fec3a3a4  0.513333\n",
       "09df3ada-e5a8-4419-b78a-e0d1e9b37484  0.277778\n",
       "09f279ac-1c34-4a84-8972-3d92b93605a7  0.361111\n",
       "0c22ce7c-4641-4bb1-97f4-7a7355f70f25  0.831481\n",
       "0e51ab2d-1a03-4d18-be33-fd21a829d19b  0.754630\n",
       "1b69eee8-ab95-49dd-8979-9fff7655964d  0.277778\n",
       "21ffd986-c219-43a0-b82f-4cc460da628d  0.831481\n",
       "24640f45-b90b-40dc-a848-9e03fdfbbf91  0.588889\n",
       "2658cecf-829f-4b91-84fa-333e1ff2533c  0.574537\n",
       "2de6fa3e-ba77-4247-97a1-ce5661997618  0.361111\n",
       "3254f476-8fe5-4b93-8ab3-0a858015fde1  0.597475\n",
       "348c9e41-2d9c-47fa-b13c-3ec96d70afcc  0.817284\n",
       "38843a0b-310a-4083-920e-4c7431c085d9  0.789899\n",
       "3de829c9-4cc0-42b6-a29b-f4d8dcb861a3  0.690909\n",
       "411f7dff-e994-433c-b5c6-a7d4adf9b010  0.361111\n",
       "5059cbd7-64ee-48c0-8942-583f9e6c67c2  0.361111\n",
       "51f195d5-1362-4a7e-9d72-3aa9ff3c437d  0.712222\n",
       "62b8fd1c-9cd2-4a31-a8a1-0641d5b8dc71  0.736869\n",
       "6d82de9d-0553-47b6-b678-d0110a069663  0.593750\n",
       "6e035130-fe33-4c6b-8712-1aefc4bc68de  0.514815\n",
       "7c99c1f8-6853-409c-a6c4-124bdfb6489f  0.753968\n",
       "85579cf2-e01c-45c5-b9e7-34b40467148d  0.828571\n",
       "8f5c408e-20c1-4f79-ac52-bb772dff6b32  0.361111\n",
       "90f54517-9a8b-43d1-9ea1-95ba35b465d4  0.277778\n",
       "95dc40d9-3710-47d7-abf0-24b825a1d0c5  0.890741\n",
       "981874cf-9246-4e1e-b23c-00d432126c4f  0.875309\n",
       "a1646881-e64e-4139-b608-f4d4a42de866  0.604938\n",
       "a2edb56d-11a9-4823-93c7-260e11d36668  0.678395\n",
       "a5a60ffa-d84a-46f1-9011-38515d1c249e  0.361111\n",
       "ac49bd61-73d3-475b-9dcd-e8f476c0c19b  0.766667\n",
       "ace2c639-8cd5-403e-8b0e-1af7faddf349  0.597475\n",
       "b3d267dc-896f-4bc9-8f9b-a6a942db579a  0.636364\n",
       "ba750de9-78de-45bb-a929-873704fe71e8  0.752525\n",
       "bd786026-bad5-4fa8-9a3a-38ca03a16412  0.736364\n",
       "c0697300-b1e0-48fd-92cd-958aa1b8a4f7  0.850000\n",
       "c0ab7c63-2f39-405a-97cf-8a0e4161c03e  0.277778\n",
       "c2ce666b-eb5f-416a-bfea-8125ff5606f3  0.670202\n",
       "c3a4c4a5-1efe-4554-ab45-60f32737a52d  0.781818\n",
       "cffa52fe-b6e2-433e-ba12-f36225f8ec5c  0.656566\n",
       "d50137ad-8dce-4274-85c5-c2b399ce7ae0  0.277778\n",
       "d5a1b3dc-4247-4f6f-8c2c-a11a4877cf01  0.767172\n",
       "d77af5c1-a742-4613-9bb6-0260e4945899  0.733333\n",
       "db8307ca-1d91-4749-b1e5-ac4bb8aba075  0.716162\n",
       "dc33f0ea-1670-4a8e-80a0-b10aa78bba24  0.937778\n",
       "de68bbf8-46d7-45f0-9111-92e64ab9499a  0.277778\n",
       "e1ae8875-a398-4dde-8f4e-4b21109784e3  0.891358\n",
       "e7042c9b-f64c-4a6a-a8c9-f2cc7fca6866  0.834568\n",
       "e8542793-c51d-4edd-9f27-f2cb6005ed39  0.686420\n",
       "eddb3434-036e-4901-a4cf-02b10326e7dc  0.896296\n",
       "ee0c5dfb-4021-4d7f-b62a-f9830df90514  0.758333\n",
       "f7ba7233-32f2-4390-b026-16acd43954f0  0.361111\n",
       "f81fbbc0-feb7-454d-b486-c24e17bccad6  0.900617\n",
       "f9143626-bfe0-4e69-b652-6d1525ab4eb0  0.361111\n",
       "fc3f3244-1ff1-4e88-b1cd-51368ad5a313  0.933333\n",
       "fd6f6837-7881-4943-8129-b7ea0f0fe1b6  0.963333"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below value is the number of rows processed in this datahunt, to be used for updating the datahunt tracking table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "773"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
